{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The goal is to create a model that is stable and performs well in the future."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# dataPath = \"../home-credit-credit-risk-model-stability/\"\n",
    "dataPath = \"../data/\"\n",
    "parquetPath = dataPath + \"parquet_files/\"\n",
    "parquetTrain = parquetPath + \"train/\"\n",
    "parquetTest = parquetPath + \"test/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Following function is just an example\n",
    "\n",
    "def set_table_dtypes(df: pl.DataFrame) -> pl.DataFrame:\n",
    "    # implement all desired dtypes for tables\n",
    "    for col in df.columns:\n",
    "        if col[-1] in (\"P\", \"A\"):\n",
    "            df = df.with_columns(pl.col(col).cast(pl.Float64).alias(col))\n",
    "\n",
    "    return df\n",
    "\n",
    "def convert_strings(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    for col in df.columns:  \n",
    "        if df[col].dtype.name in ['object', 'string']:\n",
    "            df[col] = df[col].astype(\"string\").astype('category')\n",
    "            current_categories = df[col].cat.categories\n",
    "            new_categories = current_categories.to_list() + [\"Unknown\"]\n",
    "            new_dtype = pd.CategoricalDtype(categories=new_categories, ordered=True)\n",
    "            df[col] = df[col].astype(new_dtype)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_base = pl.read_parquet(parquetTrain + 'train_base.parquet')\n",
    "train_static = pl.concat(\n",
    "    [\n",
    "        pl.read_parquet(parquetTrain + 'train_static_0_0.parquet').pipe(set_table_dtypes),\n",
    "        pl.read_parquet(parquetTrain + 'train_static_0_1.parquet').pipe(set_table_dtypes),        \n",
    "    ],\n",
    "    how='vertical_relaxed',\n",
    ")\n",
    "\n",
    "train_static_cb = pl.read_parquet(parquetTrain + 'train_static_cb_0.parquet').pipe(set_table_dtypes)\n",
    "train_person_1 = pl.read_parquet(parquetTrain + 'train_person_1.parquet').pipe(set_table_dtypes)\n",
    "train_credit_bureau_b_2 = pl.read_parquet(parquetTrain + 'train_credit_bureau_b_2.parquet').pipe(set_table_dtypes)\n",
    "\n",
    "## add line\n",
    "train_deposit_1 = pl.read_parquet(parquetTrain + 'train_deposit_1.parquet').pipe(set_table_dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_basetable = pl.read_parquet(dataPath + \"parquet_files/test/test_base.parquet\")\n",
    "test_static = pl.concat(\n",
    "    [\n",
    "        pl.read_parquet(dataPath + \"parquet_files/test/test_static_0_0.parquet\").pipe(set_table_dtypes),\n",
    "        pl.read_parquet(dataPath + \"parquet_files/test/test_static_0_1.parquet\").pipe(set_table_dtypes),\n",
    "        pl.read_parquet(dataPath + \"parquet_files/test/test_static_0_2.parquet\").pipe(set_table_dtypes),\n",
    "    ],\n",
    "    how=\"vertical_relaxed\",\n",
    ")\n",
    "test_static_cb = pl.read_parquet(dataPath + \"parquet_files/test/test_static_cb_0.parquet\").pipe(set_table_dtypes)\n",
    "test_person_1 = pl.read_parquet(dataPath + \"parquet_files/test/test_person_1.parquet\").pipe(set_table_dtypes) \n",
    "test_credit_bureau_b_2 = pl.read_parquet(dataPath + \"parquet_files/test/test_credit_bureau_b_2.parquet\").pipe(set_table_dtypes) \n",
    "\n",
    "## add line\n",
    "test_deposit_1 = pl.read_parquet(dataPath + 'parquet_files/test/test_deposit_1.parquet').pipe(set_table_dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_person_1_feats_1 = train_person_1.group_by(\"case_id\").agg(\n",
    "    pl.col(\"mainoccupationinc_384A\").max().alias(\"mainoccupationinc_384A_max\"),\n",
    "    (pl.col(\"incometype_1044T\") == \"SELFEMPLOYED\").max().alias(\"mainoccupationinc_384A_any_selfemployed\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_person_1_feats_2 = train_person_1.select([\"case_id\", \"num_group1\", \"housetype_905L\"]).filter(\n",
    "    pl.col(\"num_group1\") == 0\n",
    ").drop(\"num_group1\").rename({\"housetype_905L\": \"person_housetype\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_credit_bureau_b_2_feats = train_credit_bureau_b_2.group_by('case_id').agg(\n",
    "    pl.col('pmts_pmtsoverdue_635A').max().alias('pmts_pmtsoverdue_635A_max'),\n",
    "    (pl.col('pmts_dpdvalue_108P') > 31).max().alias('pmts_dpdvalue_108P_over31')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_deposit_1_feats = train_deposit_1.group_by('case_id').agg(pl.sum('amount_416A').alias('total_amount_A')).sort(by='case_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>case_id</th><th>total_amount_A</th></tr><tr><td>i64</td><td>f64</td></tr></thead><tbody><tr><td>225</td><td>0.0</td></tr><tr><td>331</td><td>260.374</td></tr><tr><td>358</td><td>0.0</td></tr><tr><td>390</td><td>212175.81201</td></tr><tr><td>445</td><td>23735.938</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 2)\n",
       "┌─────────┬────────────────┐\n",
       "│ case_id ┆ total_amount_A │\n",
       "│ ---     ┆ ---            │\n",
       "│ i64     ┆ f64            │\n",
       "╞═════════╪════════════════╡\n",
       "│ 225     ┆ 0.0            │\n",
       "│ 331     ┆ 260.374        │\n",
       "│ 358     ┆ 0.0            │\n",
       "│ 390     ┆ 212175.81201   │\n",
       "│ 445     ┆ 23735.938      │\n",
       "└─────────┴────────────────┘"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_deposit_1_feats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['amtinstpaidbefduel24m_4187115A', 'annuity_780A', 'annuitynextmonth_57A', 'avginstallast24m_3658937A', 'avglnamtstart24m_4525187A', 'avgoutstandbalancel6m_4187114A', 'avgpmtlast12m_4525200A', 'credamount_770A', 'currdebt_22A', 'currdebtcredtyperange_828A', 'disbursedcredamount_1113A', 'downpmt_116A', 'inittransactionamount_650A', 'lastapprcommoditycat_1041M', 'lastapprcommoditytypec_5251766M', 'lastapprcredamount_781A', 'lastcancelreason_561M', 'lastotherinc_902A', 'lastotherlnsexpense_631A', 'lastrejectcommoditycat_161M', 'lastrejectcommodtypec_5251769M', 'lastrejectcredamount_222A', 'lastrejectreason_759M', 'lastrejectreasonclient_4145040M', 'maininc_215A', 'maxannuity_159A', 'maxannuity_4075009A', 'maxdebt4_972A', 'maxinstallast24m_3658928A', 'maxlnamtstart6m_4525199A', 'maxoutstandbalancel12m_4187113A', 'maxpmtlast3m_4525190A', 'previouscontdistrict_112M', 'price_1097A', 'sumoutstandtotal_3546847A', 'sumoutstandtotalest_4493215A', 'totaldebt_9A', 'totalsettled_863A', 'totinstallast1m_4525188A']\n",
      "['description_5085714M', 'education_1103M', 'education_88M', 'maritalst_385M', 'maritalst_893M', 'pmtaverage_3A', 'pmtaverage_4527227A', 'pmtaverage_4955615A', 'pmtssum_45A']\n"
     ]
    }
   ],
   "source": [
    "# We will process in this examples only A-type and M-type columns, so we need to select them.\n",
    "selected_static_cols = []\n",
    "for col in train_static.columns:\n",
    "    if col[-1] in (\"A\", \"M\"):\n",
    "        selected_static_cols.append(col)\n",
    "print(selected_static_cols)\n",
    "\n",
    "selected_static_cb_cols = []\n",
    "for col in train_static_cb.columns:\n",
    "    if col[-1] in (\"A\", \"M\"):\n",
    "        selected_static_cb_cols.append(col)\n",
    "print(selected_static_cb_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join all tables together.\n",
    "data = train_base.join(\n",
    "    train_static.select([\"case_id\"]+selected_static_cols), how=\"left\", on=\"case_id\"\n",
    ").join(\n",
    "    train_static_cb.select([\"case_id\"]+selected_static_cb_cols), how=\"left\", on=\"case_id\"\n",
    ").join(\n",
    "    train_person_1_feats_1, how=\"left\", on=\"case_id\"\n",
    ").join(\n",
    "    train_person_1_feats_2, how=\"left\", on=\"case_id\"\n",
    ").join(\n",
    "    train_credit_bureau_b_2_feats, how=\"left\", on=\"case_id\"\n",
    ").join( ## add line\n",
    "    train_deposit_1_feats, how= \"left\", on=\"case_id\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Same on test\n",
    "test_person_1_feats_1 = test_person_1.group_by(\"case_id\").agg(\n",
    "    pl.col(\"mainoccupationinc_384A\").max().alias(\"mainoccupationinc_384A_max\"),\n",
    "    (pl.col(\"incometype_1044T\") == \"SELFEMPLOYED\").max().alias(\"mainoccupationinc_384A_any_selfemployed\")\n",
    ")\n",
    "\n",
    "test_person_1_feats_2 = test_person_1.select([\"case_id\", \"num_group1\", \"housetype_905L\"]).filter(\n",
    "    pl.col(\"num_group1\") == 0\n",
    ").drop(\"num_group1\").rename({\"housetype_905L\": \"person_housetype\"})\n",
    "\n",
    "test_credit_bureau_b_2_feats = test_credit_bureau_b_2.group_by(\"case_id\").agg(\n",
    "    pl.col(\"pmts_pmtsoverdue_635A\").max().alias(\"pmts_pmtsoverdue_635A_max\"),\n",
    "    (pl.col(\"pmts_dpdvalue_108P\") > 31).max().alias(\"pmts_dpdvalue_108P_over31\")\n",
    ")\n",
    "\n",
    "## add line\n",
    "test_deposit_1_feats = test_deposit_1.group_by('case_id').agg(pl.sum('amount_416A').alias('total_amount_A')).sort(by='case_id')\n",
    "####\n",
    "\n",
    "data_submission = test_basetable.join(\n",
    "    test_static.select([\"case_id\"]+selected_static_cols), how=\"left\", on=\"case_id\"\n",
    ").join(\n",
    "    test_static_cb.select([\"case_id\"]+selected_static_cb_cols), how=\"left\", on=\"case_id\"\n",
    ").join(\n",
    "    test_person_1_feats_1, how=\"left\", on=\"case_id\"\n",
    ").join(\n",
    "    test_person_1_feats_2, how=\"left\", on=\"case_id\"\n",
    ").join(\n",
    "    test_credit_bureau_b_2_feats, how=\"left\", on=\"case_id\"\n",
    "). join( # add\n",
    "    test_deposit_1_feats, how=\"left\", on=\"case_id\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['amtinstpaidbefduel24m_4187115A', 'annuity_780A', 'annuitynextmonth_57A', 'avginstallast24m_3658937A', 'avglnamtstart24m_4525187A', 'avgoutstandbalancel6m_4187114A', 'avgpmtlast12m_4525200A', 'credamount_770A', 'currdebt_22A', 'currdebtcredtyperange_828A', 'disbursedcredamount_1113A', 'downpmt_116A', 'inittransactionamount_650A', 'lastapprcommoditycat_1041M', 'lastapprcommoditytypec_5251766M', 'lastapprcredamount_781A', 'lastcancelreason_561M', 'lastotherinc_902A', 'lastotherlnsexpense_631A', 'lastrejectcommoditycat_161M', 'lastrejectcommodtypec_5251769M', 'lastrejectcredamount_222A', 'lastrejectreason_759M', 'lastrejectreasonclient_4145040M', 'maininc_215A', 'maxannuity_159A', 'maxannuity_4075009A', 'maxdebt4_972A', 'maxinstallast24m_3658928A', 'maxlnamtstart6m_4525199A', 'maxoutstandbalancel12m_4187113A', 'maxpmtlast3m_4525190A', 'previouscontdistrict_112M', 'price_1097A', 'sumoutstandtotal_3546847A', 'sumoutstandtotalest_4493215A', 'totaldebt_9A', 'totalsettled_863A', 'totinstallast1m_4525188A', 'description_5085714M', 'education_1103M', 'education_88M', 'maritalst_385M', 'maritalst_893M', 'pmtaverage_3A', 'pmtaverage_4527227A', 'pmtaverage_4955615A', 'pmtssum_45A', 'total_amount_A']\n"
     ]
    }
   ],
   "source": [
    "case_ids = data['case_id'].unique().shuffle(seed=1)\n",
    "case_ids_train, case_ids_test = train_test_split(case_ids, train_size=0.6, random_state=1)\n",
    "case_ids_valid, case_ids_test = train_test_split(case_ids_test, train_size=0.5, random_state=1)\n",
    "\n",
    "cols_pred = []\n",
    "for col in data.columns:\n",
    "    if col[-1].isupper() and col[:-1].islower():\n",
    "        cols_pred.append(col)\n",
    "\n",
    "print(cols_pred)\n",
    "\n",
    "def from_polars_to_pandas(case_ids: pl.DataFrame) -> pl.DataFrame:\n",
    "    return (\n",
    "        data.filter(pl.col(\"case_id\").is_in(case_ids))[[\"case_id\", \"WEEK_NUM\", \"target\"]].to_pandas(),\n",
    "        data.filter(pl.col(\"case_id\").is_in(case_ids))[cols_pred].to_pandas(),\n",
    "        data.filter(pl.col(\"case_id\").is_in(case_ids))[\"target\"].to_pandas()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_train, X_train, y_train = from_polars_to_pandas(case_ids_train)\n",
    "base_valid, X_valid, y_valid = from_polars_to_pandas(case_ids_valid)\n",
    "base_test, X_test, y_test = from_polars_to_pandas(case_ids_test)\n",
    "\n",
    "for df in [X_train, X_valid, X_test]:\n",
    "    df = convert_strings(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (915995, 49)\n",
      "Valid: (305332, 49)\n",
      "Test: (305332, 49)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train: {X_train.shape}\")\n",
    "print(f\"Valid: {X_valid.shape}\")\n",
    "print(f\"Test: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hmk40\\anaconda3\\Lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 10 rounds\n",
      "[50]\tvalid_0's auc: 0.706534\n",
      "[100]\tvalid_0's auc: 0.725415\n",
      "[150]\tvalid_0's auc: 0.732212\n",
      "[200]\tvalid_0's auc: 0.736712\n",
      "[250]\tvalid_0's auc: 0.739918\n",
      "[300]\tvalid_0's auc: 0.741934\n",
      "[350]\tvalid_0's auc: 0.743881\n",
      "[400]\tvalid_0's auc: 0.745477\n",
      "[450]\tvalid_0's auc: 0.746852\n",
      "[500]\tvalid_0's auc: 0.747866\n",
      "[550]\tvalid_0's auc: 0.748753\n",
      "[600]\tvalid_0's auc: 0.749831\n",
      "[650]\tvalid_0's auc: 0.750841\n",
      "[700]\tvalid_0's auc: 0.751625\n",
      "[750]\tvalid_0's auc: 0.752173\n",
      "Early stopping, best iteration is:\n",
      "[784]\tvalid_0's auc: 0.752741\n"
     ]
    }
   ],
   "source": [
    "lgb_train = lgb.Dataset(X_train, label=y_train)\n",
    "lgb_valid = lgb.Dataset(X_valid, label=y_valid, reference=lgb_train)\n",
    "\n",
    "params = {\n",
    "    \"boosting_type\": \"gbdt\",\n",
    "    \"objective\": \"binary\",\n",
    "    \"metric\": \"auc\",\n",
    "    \"max_depth\": 3,\n",
    "    \"num_leaves\": 31,\n",
    "    \"learning_rate\": 0.05,\n",
    "    \"feature_fraction\": 0.9,\n",
    "    \"bagging_fraction\": 0.8,\n",
    "    \"bagging_freq\": 5,\n",
    "    \"n_estimators\": 1000,\n",
    "    \"verbose\": -1,\n",
    "}\n",
    "\n",
    "gbm = lgb.train(\n",
    "    params,\n",
    "    lgb_train,\n",
    "    valid_sets=lgb_valid,\n",
    "    callbacks=[lgb.log_evaluation(50), lgb.early_stopping(10)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The AUC score on the train set is: 0.7658777233931774\n",
      "The AUC score on the valid set is: 0.7527407728341027\n",
      "The AUC score on the test set is: 0.7488949126642412\n"
     ]
    }
   ],
   "source": [
    "for base, X in [(base_train, X_train), (base_valid, X_valid), (base_test, X_test)]:\n",
    "    y_pred = gbm.predict(X, num_iteration=gbm.best_iteration)\n",
    "    base[\"score\"] = y_pred\n",
    "\n",
    "print(f'The AUC score on the train set is: {roc_auc_score(base_train[\"target\"], base_train[\"score\"])}') \n",
    "print(f'The AUC score on the valid set is: {roc_auc_score(base_valid[\"target\"], base_valid[\"score\"])}') \n",
    "print(f'The AUC score on the test set is: {roc_auc_score(base_test[\"target\"], base_test[\"score\"])}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The stability score on the train set is: 0.5011252123586621\n",
      "The stability score on the valid set is: 0.46959297053655136\n",
      "The stability score on the test set is: 0.45844926348477866\n"
     ]
    }
   ],
   "source": [
    "def gini_stability(base, w_fallingrate=88.0, w_resstd=-0.5):\n",
    "    gini_in_time = base.loc[:, [\"WEEK_NUM\", \"target\", \"score\"]]\\\n",
    "        .sort_values(\"WEEK_NUM\")\\\n",
    "        .groupby(\"WEEK_NUM\")[[\"target\", \"score\"]]\\\n",
    "        .apply(lambda x: 2*roc_auc_score(x[\"target\"], x[\"score\"])-1).tolist()\n",
    "    \n",
    "    x = np.arange(len(gini_in_time))\n",
    "    y = gini_in_time\n",
    "    a, b = np.polyfit(x, y, 1)\n",
    "    y_hat = a*x + b\n",
    "    residuals = y - y_hat\n",
    "    res_std = np.std(residuals)\n",
    "    avg_gini = np.mean(gini_in_time)\n",
    "    return avg_gini + w_fallingrate * min(0, a) + w_resstd * res_std\n",
    "\n",
    "stability_score_train = gini_stability(base_train)\n",
    "stability_score_valid = gini_stability(base_valid)\n",
    "stability_score_test = gini_stability(base_test)\n",
    "\n",
    "print(f'The stability score on the train set is: {stability_score_train}') \n",
    "print(f'The stability score on the valid set is: {stability_score_valid}') \n",
    "print(f'The stability score on the test set is: {stability_score_test}') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_submission = data_submission[cols_pred].to_pandas()\n",
    "X_submission = convert_strings(X_submission)\n",
    "categorical_cols = X_train.select_dtypes(include=['category']).columns\n",
    "\n",
    "for col in categorical_cols:\n",
    "    train_categories = set(X_train[col].cat.categories)\n",
    "    submission_categories = set(X_submission[col].cat.categories)\n",
    "    new_categories = submission_categories - train_categories\n",
    "    X_submission.loc[X_submission[col].isin(new_categories), col] = \"Unknown\"\n",
    "    new_dtype = pd.CategoricalDtype(categories=train_categories, ordered=True)\n",
    "    X_train[col] = X_train[col].astype(new_dtype)\n",
    "    X_submission[col] = X_submission[col].astype(new_dtype)\n",
    "\n",
    "y_submission_pred = gbm.predict(X_submission, num_iteration=gbm.best_iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({\n",
    "    \"case_id\": data_submission[\"case_id\"].to_numpy(),\n",
    "    \"score\": y_submission_pred\n",
    "}).set_index('case_id')\n",
    "submission.to_csv(\"./submission_deposit.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "0.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
